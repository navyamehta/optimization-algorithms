{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> This notebook presents a greedy heuristic algorithm approach to the Google HashCode Optimization Problem, more details for which can be found at https://www.kaggle.com/c/hashcode-photo-slideshow/data. Within this approach, a (nxn/2,1) heap priority queue is created to calculate \"interest metric\" values between each pair of images. The highest-value pairs are continuously appended to the string until all elements have been added. After individual horizontal and vertical images are added, a meta-level optimization is performed to club vertical images together. While this may possibly miss global minima as double-vertical slides are not considered in the initial ordering, the split reduces the computational order of magnitude. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import gc\n",
    "import psutil\n",
    "import pickle\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import collections\n",
    "import h5py\n",
    "import gc\n",
    "from sortedcontainers import SortedDict, SortedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('d_pet_pictures.txt', 'rb') as f:\n",
    "    data = f.readlines()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create Greedy Algorithm Helper Functions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tagdict(data):\n",
    "    hdict, vdict = {}, {}\n",
    "    for i in range(len(data)):\n",
    "        row = np.vectorize(lambda s: s.decode('utf-8'))(data[i].split())\n",
    "        if row[0]==\"H\": hdict[str(i)] = set(row[1:])\n",
    "        else: vdict[str(i)] = set(row[1:])\n",
    "    return hdict, vdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL VARIABLES INVARIANT\n",
    "#Needs hdict and vdict, dictionaries of image tag sets\n",
    "def calculate_interest(name1, name2):\n",
    "    #Invariant: names are of the form (H/V):K where H/V indicates the dictionary in question and K is the key\n",
    "    #The hdict and vdict dictionaries contain sets\n",
    "    namedisamb = (lambda s: hdict[s.split(\":\")[1]] if s.split(\":\")[0]==\"H\" else \n",
    "                  vdict[s.split(\":\")[1]])\n",
    "    tag1, tag2 = namedisamb(name1), namedisamb(name2)\n",
    "    return min(len(tag1&tag2), len(tag1-tag2), len(tag2-tag1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate interest master list for subset of arrays\n",
    "#Memory limitations prohibit a 90000x90000 master matrix\n",
    "def generate_interest_dict(keys):\n",
    "    start = time.time()\n",
    "    checkpoints = np.arange(0, keys.shape[0], keys.shape[0]/5)[1:]\n",
    "    interestdict = SortedDict()\n",
    "    for i in range(keys.shape[0]):\n",
    "        for j in range(i+1, keys.shape[0]):\n",
    "            value = calculate_interest(keys[i], keys[j])\n",
    "            if value==0: continue\n",
    "            if interestdict.get(value, False)==False:\n",
    "                interestdict[value] = collections.deque([(i,j)])\n",
    "            else:\n",
    "                interestdict[value].append((i,j))\n",
    "        if (i+1) in checkpoints: \n",
    "            print(\"Calculation Checkpoint of \"+str(i+1)+\":\"+str(time.time()-start))\n",
    "    print(time.time()-start)\n",
    "    return interestdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#interestdict: a sorted dictionaries of deques containing interest values\n",
    "#lookupdict: a dictionary of occurences\n",
    "#keys: list of names of keys\n",
    "def getmaxfn(interestdict, lookupdict, keys):\n",
    "    curcount1, curcount2 = 2, 2\n",
    "    while (curcount1==2) or (curcount2==2):\n",
    "        if len(interestdict)==0: return None, False\n",
    "        curval = interestdict.keys()[-1]\n",
    "        curmax = interestdict[curval].pop()\n",
    "        curcount1, curcount2 = lookupdict.get(keys[curmax[0]],0), lookupdict.get(keys[curmax[1]],0)\n",
    "        if not interestdict[curval]:\n",
    "            del interestdict[curval]\n",
    "    lookupdict[keys[curmax[0]]] = curcount1+1\n",
    "    lookupdict[keys[curmax[1]]] = curcount2+1\n",
    "    return (keys[curmax[0]], keys[curmax[1]]), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collapse Deque\n",
    "#PARAMETERS:\n",
    "#pair: size-2 tuple containing the new added transition\n",
    "#curarrang: a deque of deques containing current valid transition sequences\n",
    "#lookupdict: a dictionary recording occurences\n",
    "def deque_update(pair, curarrang, lookupdict):\n",
    "    #Resolve Merge of Two Elements\n",
    "    def resolve_double(first, second):\n",
    "        #INVARIANT: The first and second will have an overlapping value as the first was updated but not second\n",
    "        if curarrang[first][0] in [curarrang[second][0], curarrang[second][-1]]:\n",
    "            curarrang[first].reverse()\n",
    "        if curarrang[first][-1]==curarrang[second][0]:\n",
    "            curarrang[second].popleft()\n",
    "        elif curarrang[first][-1]==curarrang[second][-1]:\n",
    "            curarrang[second].reverse()\n",
    "            curarrang[second].popleft()\n",
    "        curarrang[first]+=curarrang[second]\n",
    "        del curarrang[second]\n",
    "    match, lastm = False, 0\n",
    "    i=0\n",
    "    while i<len(curarrang):\n",
    "        if curarrang[i][0]==pair[0]:\n",
    "            #Prevent circular deques\n",
    "            if curarrang[i][-1]==pair[1]: \n",
    "                lookupdict[pair[0]]-=1\n",
    "                lookupdict[pair[1]]-=1\n",
    "                return\n",
    "            if not match:\n",
    "                curarrang[i].appendleft(pair[1])\n",
    "                lastm =  i\n",
    "                match = True\n",
    "                i+=1\n",
    "            else:\n",
    "                resolve_double(lastm, i)\n",
    "        elif curarrang[i][0]==pair[1]:\n",
    "            if curarrang[i][-1]==pair[0]: \n",
    "                lookupdict[pair[0]]-=1\n",
    "                lookupdict[pair[1]]-=1\n",
    "                return\n",
    "            if not match:\n",
    "                curarrang[i].appendleft(pair[0])\n",
    "                lastm =  i\n",
    "                match = True\n",
    "                i+=1\n",
    "            else:\n",
    "                resolve_double(lastm, i)\n",
    "        elif curarrang[i][-1]==pair[0]:\n",
    "            if curarrang[i][0]==pair[1]: \n",
    "                lookupdict[pair[0]]-=1\n",
    "                lookupdict[pair[1]]-=1\n",
    "                return\n",
    "            if not match:\n",
    "                curarrang[i].append(pair[1])\n",
    "                lastm =  i\n",
    "                match = True\n",
    "                i+=1\n",
    "            else:\n",
    "                resolve_double(lastm, i)\n",
    "        elif curarrang[i][-1]==pair[1]:\n",
    "            if curarrang[i][-1]==pair[0]:\n",
    "                lookupdict[pair[0]]-=1\n",
    "                lookupdict[pair[1]]-=1\n",
    "                return\n",
    "            if not match:\n",
    "                curarrang[i].append(pair[0])\n",
    "                lastm =  i\n",
    "                match = True\n",
    "                i+=1\n",
    "            else:\n",
    "                resolve_double(lastm, i)\n",
    "        else:\n",
    "            i+=1\n",
    "    if match: return\n",
    "    curarrang.append(collections.deque(pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Run Single-Image Greedy Heuristic (Layer 1)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "nsplits = 4\n",
    "hdict, vdict = generate_tagdict(data)\n",
    "hkeys = np.vectorize(lambda s: \"H:\"+str(s))(np.array(list(hdict.keys())))\n",
    "vkeys = np.vectorize(lambda s: \"V:\"+str(s))(np.array(list(vdict.keys())))\n",
    "totalkeys = np.append(hkeys, vkeys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(totalkeys.shape[0])\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(indices)\n",
    "indices = np.split(indices, nsplits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_run(keys):\n",
    "    interestdict = generate_interest_dict(keys)\n",
    "    lookupdict = {}\n",
    "    curarrang = collections.deque()\n",
    "    while (len(curarrang)==0) or (len(curarrang[0])<len(keys)):\n",
    "        maxval, valid = getmaxfn(interestdict, lookupdict, keys)\n",
    "        #In case all positive interest metrics have been exhausted\n",
    "        if not valid: break\n",
    "        deque_update(maxval, curarrang, lookupdict)\n",
    "    finalarrang = collections.deque()\n",
    "    for arrang in curarrang:\n",
    "        finalarrang+=arrang\n",
    "    del curarrang\n",
    "    remimg = set(keys)-set(finalarrang)\n",
    "    for img in remimg:\n",
    "        finalarrang.append(img)\n",
    "    return finalarrang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation Checkpoint of 4500:424.9527807235718\n",
      "Calculation Checkpoint of 9000:822.3509747982025\n",
      "Calculation Checkpoint of 13500:1063.8601069450378\n",
      "Calculation Checkpoint of 18000:1207.6297268867493\n",
      "1255.2410807609558\n",
      "Mask Optimized in 2244.443123102188 seconds\n",
      "Calculation Checkpoint of 4500:444.54129004478455\n",
      "Calculation Checkpoint of 9000:794.7886159420013\n",
      "Calculation Checkpoint of 13500:1043.4002268314362\n",
      "Calculation Checkpoint of 18000:1190.953207731247\n",
      "1237.5998117923737\n",
      "Mask Optimized in 2285.985775947571 seconds\n",
      "Calculation Checkpoint of 4500:464.16116309165955\n",
      "Calculation Checkpoint of 9000:815.0599539279938\n",
      "Calculation Checkpoint of 13500:1061.4540979862213\n",
      "Calculation Checkpoint of 18000:1215.1491250991821\n",
      "1261.6071569919586\n",
      "Mask Optimized in 2252.183938741684 seconds\n",
      "Calculation Checkpoint of 4500:421.3487648963928\n",
      "Calculation Checkpoint of 9000:752.308002948761\n",
      "Calculation Checkpoint of 13500:993.1060469150543\n",
      "Calculation Checkpoint of 18000:1132.5027568340302\n",
      "1177.8050417900085\n",
      "Mask Optimized in 2160.84285902977 seconds\n"
     ]
    }
   ],
   "source": [
    "finalresults = collections.deque()\n",
    "for mask in indices:\n",
    "    start = time.time()\n",
    "    arrang = individual_run(totalkeys[mask])\n",
    "    gc.collect()\n",
    "    finalresults.append(arrang)\n",
    "    print(\"Mask Optimized in \"+str(time.time()-start)+\" seconds\")\n",
    "pickle.dump(finalresults, open(\"./layer1arrang.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Generate Helper Functions for Replacement of Double-Vertical Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Group Double-Vertical Images to Enhance Interest (Layer 2) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Finalize and Write Submission File </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
